{"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Knowledge Distillation","metadata":{"id":"jkqr2HlzLB9a"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\ntf.random.set_seed(3)","metadata":{"id":"JVOwnv_VLB9f","execution":{"iopub.status.busy":"2024-01-01T12:20:36.227512Z","iopub.execute_input":"2024-01-01T12:20:36.227857Z","iopub.status.idle":"2024-01-01T12:20:47.835686Z","shell.execute_reply.started":"2024-01-01T12:20:36.227832Z","shell.execute_reply":"2024-01-01T12:20:47.834845Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"class Distiller(keras.Model):\n    def __init__(self, student, teacher):\n        super(Distiller, self).__init__()\n        self.teacher = teacher\n        self.student = student\n\n    def compile(\n        self,\n        optimizer,\n        metrics,\n        student_loss_fn,\n        distillation_loss_fn,\n        alpha=0.1,\n        temperature=3,\n    ):\n        \"\"\" Configure the distiller.\n\n        Args:\n            optimizer: Keras optimizer for the student weights\n            metrics: Keras metrics for evaluation\n            student_loss_fn: Loss function of difference between student\n                predictions and ground-truth\n            distillation_loss_fn: Loss function of difference between soft\n                student predictions and soft teacher predictions\n            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n            temperature: Temperature for softening probability distributions.\n                Larger temperature gives softer distributions.\n        \"\"\"\n        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n        self.student_loss_fn = student_loss_fn\n        self.distillation_loss_fn = distillation_loss_fn\n        self.alpha = alpha\n        self.temperature = temperature\n\n    def train_step(self, data):\n        # Unpack data\n        x, y = data\n\n        # Forward pass of teacher\n        teacher_predictions = self.teacher(x, training=False)\n\n        with tf.GradientTape() as tape:\n            # Forward pass of student\n            student_predictions = self.student(x, training=True)\n\n            # Compute losses\n            student_loss = self.student_loss_fn(y, student_predictions)\n            distillation_loss = self.distillation_loss_fn(\n                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n            )\n            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n\n        # Compute gradients\n        trainable_vars = self.student.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n\n        # Update weights\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n\n        # Update the metrics configured in `compile()`.\n        self.compiled_metrics.update_state(y, student_predictions)\n\n        # Return a dict of performance\n        results = {m.name: m.result() for m in self.metrics}\n        results.update(\n            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n        )\n        return results\n\n    def test_step(self, data):\n        # Unpack the data\n        x, y = data\n\n        # Compute predictions\n        y_prediction = self.student(x, training=False)\n\n        # Calculate the loss\n        student_loss = self.student_loss_fn(y, y_prediction)\n\n        # Update the metrics.\n        self.compiled_metrics.update_state(y, y_prediction)\n\n        # Return a dict of performance\n        results = {m.name: m.result() for m in self.metrics}\n        results.update({\"student_loss\": student_loss})\n        return results\n","metadata":{"id":"Jxg7IWuJLB9g","execution":{"iopub.status.busy":"2024-01-01T12:21:28.554685Z","iopub.execute_input":"2024-01-01T12:21:28.555059Z","iopub.status.idle":"2024-01-01T12:21:28.569132Z","shell.execute_reply.started":"2024-01-01T12:21:28.555031Z","shell.execute_reply":"2024-01-01T12:21:28.568131Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create the teacher\nteacher = keras.Sequential(\n    [\n        keras.Input(shape=(28, 28, 1)),\n        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n        layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.Flatten(),\n        layers.Dense(10),\n    ],\n    name=\"teacher\",\n)\n\n# Create the student\nstudent = keras.Sequential(\n    [\n        keras.Input(shape=(28, 28, 1)),\n        layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n        layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.Flatten(),\n        layers.Dense(10),\n    ],\n    name=\"student\",\n)\n\nstudent_scratch = keras.Sequential(\n    [\n        keras.Input(shape=(28, 28, 1)),\n        layers.Conv2D(8, (3, 3), strides=(2, 2), padding=\"same\"),\n        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n        layers.Flatten(),\n        layers.Dense(10),\n    ],\n    name=\"student_scratch\",\n)\n\n# Clone student for later comparison\n#student_scratch = keras.models.clone_model(student)","metadata":{"id":"E3nCUjusLB9i","execution":{"iopub.status.busy":"2024-01-01T12:21:29.822821Z","iopub.execute_input":"2024-01-01T12:21:29.823517Z","iopub.status.idle":"2024-01-01T12:21:29.949148Z","shell.execute_reply.started":"2024-01-01T12:21:29.823488Z","shell.execute_reply":"2024-01-01T12:21:29.948388Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"teacher.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HY1UzO-XP0Y7","outputId":"c4b9bf03-b478-410b-9784-74af3ed502ac","execution":{"iopub.status.busy":"2024-01-01T12:21:33.942958Z","iopub.execute_input":"2024-01-01T12:21:33.943817Z","iopub.status.idle":"2024-01-01T12:21:33.965126Z","shell.execute_reply.started":"2024-01-01T12:21:33.943788Z","shell.execute_reply":"2024-01-01T12:21:33.964268Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"teacher\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_5 (Conv2D)           (None, 14, 14, 256)       2560      \n                                                                 \n leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 256)       0         \n                                                                 \n max_pooling2d_3 (MaxPoolin  (None, 14, 14, 256)       0         \n g2D)                                                            \n                                                                 \n conv2d_6 (Conv2D)           (None, 7, 7, 512)         1180160   \n                                                                 \n flatten_3 (Flatten)         (None, 25088)             0         \n                                                                 \n dense_3 (Dense)             (None, 10)                250890    \n                                                                 \n=================================================================\nTotal params: 1433610 (5.47 MB)\nTrainable params: 1433610 (5.47 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"student.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_7nilDoP3vw","outputId":"df0bf7af-6abb-4bdf-a46d-83ff9a52aeb3","execution":{"iopub.status.busy":"2024-01-01T12:21:39.423850Z","iopub.execute_input":"2024-01-01T12:21:39.424220Z","iopub.status.idle":"2024-01-01T12:21:39.452127Z","shell.execute_reply.started":"2024-01-01T12:21:39.424190Z","shell.execute_reply":"2024-01-01T12:21:39.451180Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"student\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_7 (Conv2D)           (None, 14, 14, 8)         80        \n                                                                 \n leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 8)         0         \n                                                                 \n max_pooling2d_4 (MaxPoolin  (None, 14, 14, 8)         0         \n g2D)                                                            \n                                                                 \n conv2d_8 (Conv2D)           (None, 7, 7, 8)           584       \n                                                                 \n flatten_4 (Flatten)         (None, 392)               0         \n                                                                 \n dense_4 (Dense)             (None, 10)                3930      \n                                                                 \n=================================================================\nTotal params: 4594 (17.95 KB)\nTrainable params: 4594 (17.95 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"student_scratch.summary()","metadata":{"id":"mHQBpaflxQcc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"60cc9b71-ed47-4668-bbc1-0445be63f372","execution":{"iopub.status.busy":"2024-01-01T12:21:41.571836Z","iopub.execute_input":"2024-01-01T12:21:41.572471Z","iopub.status.idle":"2024-01-01T12:21:41.592168Z","shell.execute_reply.started":"2024-01-01T12:21:41.572440Z","shell.execute_reply":"2024-01-01T12:21:41.591299Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"student_scratch\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_9 (Conv2D)           (None, 14, 14, 8)         80        \n                                                                 \n max_pooling2d_5 (MaxPoolin  (None, 14, 14, 8)         0         \n g2D)                                                            \n                                                                 \n flatten_5 (Flatten)         (None, 1568)              0         \n                                                                 \n dense_5 (Dense)             (None, 10)                15690     \n                                                                 \n=================================================================\nTotal params: 15770 (61.60 KB)\nTrainable params: 15770 (61.60 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prepare the train and test dataset.\nbatch_size = 128\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n\n# Normalize data\nx_train = x_train.astype(\"float32\") / 255.0\nx_train = np.reshape(x_train, (-1, 28, 28, 1))\n\nx_test = x_test.astype(\"float32\") / 255.0\nx_test = np.reshape(x_test, (-1, 28, 28, 1))\n","metadata":{"id":"_rfIdaldLB9j","outputId":"db717600-241e-4a7b-f91f-60eb2931d9a2","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-01-01T12:21:57.147063Z","iopub.execute_input":"2024-01-01T12:21:57.147475Z","iopub.status.idle":"2024-01-01T12:21:59.426883Z","shell.execute_reply.started":"2024-01-01T12:21:57.147443Z","shell.execute_reply":"2024-01-01T12:21:59.426016Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train teacher as usual\nteacher.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\n# Train and evaluate teacher on data.\nteacher.fit(x_train, y_train, epochs=5)\nprint(\"---Testing Accuracy---\")\nteacher.evaluate(x_test, y_test)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q-QiJAHCLB9k","outputId":"337994b2-683e-4642-bb3c-4fd712bd5f07","execution":{"iopub.status.busy":"2024-01-01T12:22:13.154301Z","iopub.execute_input":"2024-01-01T12:22:13.154663Z","iopub.status.idle":"2024-01-01T12:23:07.427858Z","shell.execute_reply.started":"2024-01-01T12:22:13.154634Z","shell.execute_reply":"2024-01-01T12:23:07.427019Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1875/1875 [==============================] - 17s 5ms/step - loss: 0.1427 - sparse_categorical_accuracy: 0.9571\nEpoch 2/5\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9733\nEpoch 3/5\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9759\nEpoch 4/5\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9788\nEpoch 5/5\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9806\n---Testing Accuracy---\n313/313 [==============================] - 1s 3ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9730\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[0.1092146635055542, 0.9729999899864197]"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize and compile distiller\ndistiller = Distiller(student=student, teacher=teacher)\ndistiller.compile(\n    optimizer=keras.optimizers.Adam(),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    distillation_loss_fn=keras.losses.KLDivergence(),\n    alpha=0.1,\n    temperature=40,\n)\n\n# Distill teacher to student\ndistiller.fit(x_train, y_train, epochs=5)\nprint(\"---Testing Accuracy---\")\n# Evaluate student on test dataset\ndistiller.evaluate(x_test, y_test)","metadata":{"id":"4r3lsaYiLB9l","execution":{"iopub.status.busy":"2024-01-01T12:23:17.254065Z","iopub.execute_input":"2024-01-01T12:23:17.254887Z","iopub.status.idle":"2024-01-01T12:24:00.193017Z","shell.execute_reply.started":"2024-01-01T12:23:17.254855Z","shell.execute_reply":"2024-01-01T12:24:00.192221Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1875/1875 [==============================] - 7s 3ms/step - sparse_categorical_accuracy: 0.8979 - student_loss: 0.3364 - distillation_loss: 0.0153\nEpoch 2/5\n1875/1875 [==============================] - 6s 3ms/step - sparse_categorical_accuracy: 0.9539 - student_loss: 0.1616 - distillation_loss: 0.0080\nEpoch 3/5\n1875/1875 [==============================] - 6s 3ms/step - sparse_categorical_accuracy: 0.9591 - student_loss: 0.1422 - distillation_loss: 0.0067\nEpoch 4/5\n1875/1875 [==============================] - 6s 3ms/step - sparse_categorical_accuracy: 0.9635 - student_loss: 0.1274 - distillation_loss: 0.0061\nEpoch 5/5\n1875/1875 [==============================] - 6s 3ms/step - sparse_categorical_accuracy: 0.9670 - student_loss: 0.1159 - distillation_loss: 0.0056\n---Testing Accuracy---\n313/313 [==============================] - 1s 2ms/step - sparse_categorical_accuracy: 0.9688 - student_loss: 0.1071\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[0.9688000082969666, 0.0012940376764163375]"},"metadata":{}}]},{"cell_type":"code","source":"# Train student as done usually\nstudent_scratch.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\n# Train and evaluate student trained from scratch.\nstudent_scratch.fit(x_train, y_train, epochs=5)\nstudent_scratch.evaluate(x_test, y_test)","metadata":{"id":"-b77WIjOLB9m","execution":{"iopub.status.busy":"2024-01-01T12:24:00.194689Z","iopub.execute_input":"2024-01-01T12:24:00.195497Z","iopub.status.idle":"2024-01-01T12:24:25.525561Z","shell.execute_reply.started":"2024-01-01T12:24:00.195459Z","shell.execute_reply":"2024-01-01T12:24:25.524647Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1875/1875 [==============================] - 6s 3ms/step - loss: 0.2800 - sparse_categorical_accuracy: 0.9208\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9671\nEpoch 3/5\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9739\nEpoch 4/5\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9776\nEpoch 5/5\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9795\n313/313 [==============================] - 1s 2ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9760\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[0.07634099572896957, 0.9760000109672546]"},"metadata":{}}]}]}